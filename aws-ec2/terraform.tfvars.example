# Ladybugs Terraform Configuration
# Copy this file to terraform.tfvars and fill in your values
# IMPORTANT: Never commit terraform.tfvars to version control (it contains secrets)

# AWS Configuration
aws_region = "us-east-1"

# Instance Configuration
# t3.large (2 vCPU, 8GB RAM) is recommended for production
# t3.medium (2 vCPU, 4GB RAM) is minimum viable
# t3.xlarge (4 vCPU, 16GB RAM) for heavy usage
instance_type = "t3.large"

# Storage size in GB (50GB recommended, expandable later)
volume_size = 50

# SSH key pair name (must exist in AWS, leave empty to disable SSH)
# Create one in AWS Console: EC2 > Key Pairs > Create key pair
key_name = ""

# Network Security
# Restrict these to your IP for better security (e.g., ["1.2.3.4/32"])
allowed_ssh_cidrs = ["0.0.0.0/0"]
allowed_api_cidrs = ["0.0.0.0/0"]

# Docker Hub token (required - provided by Ladybugs team)
docker_hub_token = "your-docker-hub-token-here"

# =============================================================================
# Secrets Management Options
# =============================================================================
# You have three options for managing environment variables:
#
# OPTION 1: Direct mode (default)
#   - Set ladybugs_env_vars below
#   - Variables are written directly to .env file on EC2
#   - Simple but secrets are stored in Terraform state
#
# OPTION 2: Use existing Secrets Manager
#   - Set secrets_manager_arn to your existing secret's ARN
#   - EC2 fetches secrets at runtime via IAM role
#   - Your secret must be JSON format: {"KEY": "value", ...}
#
# OPTION 3: Create new Secrets Manager
#   - Set create_secrets_manager = true
#   - Set ladybugs_env_vars with your secrets
#   - Module creates the secret, EC2 fetches at runtime
#   - Best of both worlds: easy config + secure storage
# =============================================================================

# -----------------------------------------------------------------------------
# OPTION 1: Direct environment variables (default)
# -----------------------------------------------------------------------------
# These are written to /opt/ladybugs/.env on the server
ladybugs_env_vars = {
  # Required
  "AI_PROVIDER_API_KEY" = "your-ai-provider-api-key"

  # Optional - uncomment and configure as needed
  # "PORT" = "5000"
  # "AI_PROVIDER_MODE" = "Live"

  # Slack Integration
  # "SLACK_BOT_TOKEN" = "xoxb-your-token"
  # "SLACK_SIGNING_SECRET" = "your-signing-secret"

  # Jira Integration
  # "JIRA_WEBHOOK_SECRET" = "your-webhook-secret"

  # Log Systems
  # "CLOUDWATCH_ACCESS_KEY_ID" = "your-aws-key"
  # "CLOUDWATCH_SECRET_ACCESS_KEY" = "your-aws-secret"
  # "CORALOGIX_API_KEY" = "your-coralogix-key"
  # "GRAFANA_API_KEY" = "your-grafana-key"
}

# -----------------------------------------------------------------------------
# OPTION 2: Use existing AWS Secrets Manager secret
# -----------------------------------------------------------------------------
# Uncomment to use an existing secret (must be JSON format)
# secrets_manager_arn = "arn:aws:secretsmanager:us-east-1:123456789012:secret:my-ladybugs-secrets-AbCdEf"

# -----------------------------------------------------------------------------
# OPTION 3: Create new AWS Secrets Manager secret
# -----------------------------------------------------------------------------
# Uncomment to have the module create a Secrets Manager secret from ladybugs_env_vars
# create_secrets_manager = true
# secrets_manager_name = "ladybugs-production-env"  # Optional: custom name for the secret

# -----------------------------------------------------------------------------
# EFS Configuration (External Logs)
# -----------------------------------------------------------------------------
# Mount an existing EFS file system for external log analysis.
# This allows Ladybugs to read logs from other AWS services stored on EFS.
#
# Prerequisites:
#   1. Create an EFS file system in the AWS Console or via Terraform
#   2. Ensure the EFS is in the same region as your EC2 instance
#   3. Provide the file system ID below
#
# How it works:
#   - EFS is mounted at /mnt/efs/logs on the EC2 instance
#   - Container accesses logs at /app/external-logs
#   - Each top-level directory in EFS is treated as a "service"
#   - The External Logs Agent can query all logs with regex patterns
#
# Directory structure example:
#   /mnt/efs/logs/
#   ├── api-service/
#   │   ├── app.log
#   │   └── error.log
#   ├── payment-service/
#   │   └── transactions.log
#   └── auth-service/
#       └── login.log

# Uncomment to enable EFS mounting
# efs_file_system_id = "fs-0123456789abcdef0"  # Your EFS file system ID
# efs_mount_path = "/mnt/efs/logs"  # Optional: customize mount path (default: /mnt/efs/logs)

# Resource tagging
environment  = "production"
project_name = "ladybugs"
